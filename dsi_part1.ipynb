{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSI Instructor Task Part 1: Modeling\n",
    "### Background\n",
    "In this challenge, we'll be working with a dataset which includes measurements of breast cancer cells. The task is to predict for each cell, whether is it malignant or benign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "Load in the data file and header file provided and attach it to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>radius_sd_error</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>texture_sd_error</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>perimeter_sd_error</th>\n",
       "      <th>...</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>concave_points_sd_error</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>symmetry_sd_error</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>fractal_dimension_sd_error</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>...</td>\n",
       "      <td>15.470</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.880</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.14420</td>\n",
       "      <td>0.25760</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>0.059850</td>\n",
       "      <td>...</td>\n",
       "      <td>17.060</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.16540</td>\n",
       "      <td>0.36820</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>...</td>\n",
       "      <td>15.490</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>...</td>\n",
       "      <td>15.090</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.18530</td>\n",
       "      <td>1.05800</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>845636</td>\n",
       "      <td>M</td>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>...</td>\n",
       "      <td>19.190</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>0.15510</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84610002</td>\n",
       "      <td>M</td>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.099540</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>...</td>\n",
       "      <td>20.420</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.13960</td>\n",
       "      <td>0.56090</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846226</td>\n",
       "      <td>M</td>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.39030</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>846381</td>\n",
       "      <td>M</td>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.099380</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>...</td>\n",
       "      <td>16.840</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.19240</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84667401</td>\n",
       "      <td>M</td>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.080250</td>\n",
       "      <td>...</td>\n",
       "      <td>15.030</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.16510</td>\n",
       "      <td>0.77250</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84799002</td>\n",
       "      <td>M</td>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.073640</td>\n",
       "      <td>...</td>\n",
       "      <td>17.460</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.65770</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>848406</td>\n",
       "      <td>M</td>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>...</td>\n",
       "      <td>19.070</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84862001</td>\n",
       "      <td>M</td>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.960</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.42330</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>849014</td>\n",
       "      <td>M</td>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>...</td>\n",
       "      <td>27.320</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>0.31500</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8510426</td>\n",
       "      <td>B</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.066640</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8510824</td>\n",
       "      <td>B</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8511133</td>\n",
       "      <td>M</td>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.097560</td>\n",
       "      <td>...</td>\n",
       "      <td>18.070</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.59540</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>851509</td>\n",
       "      <td>M</td>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>...</td>\n",
       "      <td>29.170</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>852552</td>\n",
       "      <td>M</td>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>...</td>\n",
       "      <td>26.460</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.18050</td>\n",
       "      <td>0.35780</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>852631</td>\n",
       "      <td>M</td>\n",
       "      <td>17.140</td>\n",
       "      <td>16.40</td>\n",
       "      <td>116.00</td>\n",
       "      <td>912.7</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.22760</td>\n",
       "      <td>0.222900</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>...</td>\n",
       "      <td>22.250</td>\n",
       "      <td>21.40</td>\n",
       "      <td>152.40</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.39490</td>\n",
       "      <td>0.38530</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.4066</td>\n",
       "      <td>0.10590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>852763</td>\n",
       "      <td>M</td>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>...</td>\n",
       "      <td>17.620</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.66430</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>852781</td>\n",
       "      <td>M</td>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>...</td>\n",
       "      <td>21.310</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>0.21170</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>852973</td>\n",
       "      <td>M</td>\n",
       "      <td>15.300</td>\n",
       "      <td>25.27</td>\n",
       "      <td>102.40</td>\n",
       "      <td>732.4</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>...</td>\n",
       "      <td>20.270</td>\n",
       "      <td>36.71</td>\n",
       "      <td>149.30</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>0.16410</td>\n",
       "      <td>0.61100</td>\n",
       "      <td>0.63350</td>\n",
       "      <td>0.20240</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.09876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>853201</td>\n",
       "      <td>M</td>\n",
       "      <td>17.570</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.098750</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>...</td>\n",
       "      <td>20.010</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.28120</td>\n",
       "      <td>0.24890</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>921362</td>\n",
       "      <td>B</td>\n",
       "      <td>7.691</td>\n",
       "      <td>25.44</td>\n",
       "      <td>48.34</td>\n",
       "      <td>170.4</td>\n",
       "      <td>0.08668</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>...</td>\n",
       "      <td>8.678</td>\n",
       "      <td>31.89</td>\n",
       "      <td>54.49</td>\n",
       "      <td>223.6</td>\n",
       "      <td>0.15960</td>\n",
       "      <td>0.30640</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.10660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>921385</td>\n",
       "      <td>B</td>\n",
       "      <td>11.540</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>...</td>\n",
       "      <td>12.260</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.13450</td>\n",
       "      <td>0.21180</td>\n",
       "      <td>0.17970</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>921386</td>\n",
       "      <td>B</td>\n",
       "      <td>14.470</td>\n",
       "      <td>24.99</td>\n",
       "      <td>95.81</td>\n",
       "      <td>656.4</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>...</td>\n",
       "      <td>16.220</td>\n",
       "      <td>31.73</td>\n",
       "      <td>113.50</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.13400</td>\n",
       "      <td>0.42020</td>\n",
       "      <td>0.40400</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>921644</td>\n",
       "      <td>B</td>\n",
       "      <td>14.740</td>\n",
       "      <td>25.42</td>\n",
       "      <td>94.70</td>\n",
       "      <td>668.6</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.07214</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>...</td>\n",
       "      <td>16.510</td>\n",
       "      <td>32.29</td>\n",
       "      <td>107.40</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.13760</td>\n",
       "      <td>0.16110</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.06956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>922296</td>\n",
       "      <td>B</td>\n",
       "      <td>13.210</td>\n",
       "      <td>28.06</td>\n",
       "      <td>84.88</td>\n",
       "      <td>538.4</td>\n",
       "      <td>0.08671</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>...</td>\n",
       "      <td>14.370</td>\n",
       "      <td>37.17</td>\n",
       "      <td>92.48</td>\n",
       "      <td>629.6</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.13810</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.07958</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>0.06443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>922297</td>\n",
       "      <td>B</td>\n",
       "      <td>13.870</td>\n",
       "      <td>20.70</td>\n",
       "      <td>89.77</td>\n",
       "      <td>584.8</td>\n",
       "      <td>0.09578</td>\n",
       "      <td>0.10180</td>\n",
       "      <td>0.036880</td>\n",
       "      <td>0.023690</td>\n",
       "      <td>...</td>\n",
       "      <td>15.050</td>\n",
       "      <td>24.75</td>\n",
       "      <td>99.17</td>\n",
       "      <td>688.6</td>\n",
       "      <td>0.12640</td>\n",
       "      <td>0.20370</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>0.06845</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.08492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>922576</td>\n",
       "      <td>B</td>\n",
       "      <td>13.620</td>\n",
       "      <td>23.23</td>\n",
       "      <td>87.19</td>\n",
       "      <td>573.2</td>\n",
       "      <td>0.09246</td>\n",
       "      <td>0.06747</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>...</td>\n",
       "      <td>15.350</td>\n",
       "      <td>29.09</td>\n",
       "      <td>97.58</td>\n",
       "      <td>729.8</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.10490</td>\n",
       "      <td>0.07174</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.06953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>922577</td>\n",
       "      <td>B</td>\n",
       "      <td>10.320</td>\n",
       "      <td>16.35</td>\n",
       "      <td>65.31</td>\n",
       "      <td>324.9</td>\n",
       "      <td>0.09434</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>...</td>\n",
       "      <td>11.250</td>\n",
       "      <td>21.77</td>\n",
       "      <td>71.12</td>\n",
       "      <td>384.9</td>\n",
       "      <td>0.12850</td>\n",
       "      <td>0.08842</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.2681</td>\n",
       "      <td>0.07399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>922840</td>\n",
       "      <td>B</td>\n",
       "      <td>10.260</td>\n",
       "      <td>16.58</td>\n",
       "      <td>65.85</td>\n",
       "      <td>320.8</td>\n",
       "      <td>0.08877</td>\n",
       "      <td>0.08066</td>\n",
       "      <td>0.043580</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>...</td>\n",
       "      <td>10.830</td>\n",
       "      <td>22.04</td>\n",
       "      <td>71.08</td>\n",
       "      <td>357.4</td>\n",
       "      <td>0.14610</td>\n",
       "      <td>0.22460</td>\n",
       "      <td>0.17830</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.09479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>923169</td>\n",
       "      <td>B</td>\n",
       "      <td>9.683</td>\n",
       "      <td>19.34</td>\n",
       "      <td>61.05</td>\n",
       "      <td>285.7</td>\n",
       "      <td>0.08491</td>\n",
       "      <td>0.05030</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>...</td>\n",
       "      <td>10.930</td>\n",
       "      <td>25.59</td>\n",
       "      <td>69.10</td>\n",
       "      <td>364.2</td>\n",
       "      <td>0.11990</td>\n",
       "      <td>0.09546</td>\n",
       "      <td>0.09350</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.07920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>923465</td>\n",
       "      <td>B</td>\n",
       "      <td>10.820</td>\n",
       "      <td>24.21</td>\n",
       "      <td>68.89</td>\n",
       "      <td>361.6</td>\n",
       "      <td>0.08192</td>\n",
       "      <td>0.06602</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>...</td>\n",
       "      <td>13.030</td>\n",
       "      <td>31.45</td>\n",
       "      <td>83.90</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.16330</td>\n",
       "      <td>0.06194</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.07626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>923748</td>\n",
       "      <td>B</td>\n",
       "      <td>10.860</td>\n",
       "      <td>21.48</td>\n",
       "      <td>68.51</td>\n",
       "      <td>360.5</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.04227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.660</td>\n",
       "      <td>24.77</td>\n",
       "      <td>74.08</td>\n",
       "      <td>412.3</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>923780</td>\n",
       "      <td>B</td>\n",
       "      <td>11.130</td>\n",
       "      <td>22.44</td>\n",
       "      <td>71.49</td>\n",
       "      <td>378.4</td>\n",
       "      <td>0.09566</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>0.048240</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020</td>\n",
       "      <td>28.26</td>\n",
       "      <td>77.80</td>\n",
       "      <td>436.6</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.17820</td>\n",
       "      <td>0.15640</td>\n",
       "      <td>0.06413</td>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.08032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>924084</td>\n",
       "      <td>B</td>\n",
       "      <td>12.770</td>\n",
       "      <td>29.43</td>\n",
       "      <td>81.35</td>\n",
       "      <td>507.9</td>\n",
       "      <td>0.08276</td>\n",
       "      <td>0.04234</td>\n",
       "      <td>0.019970</td>\n",
       "      <td>0.014990</td>\n",
       "      <td>...</td>\n",
       "      <td>13.870</td>\n",
       "      <td>36.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>594.7</td>\n",
       "      <td>0.12340</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08653</td>\n",
       "      <td>0.06498</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.06484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>924342</td>\n",
       "      <td>B</td>\n",
       "      <td>9.333</td>\n",
       "      <td>21.94</td>\n",
       "      <td>59.01</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.09240</td>\n",
       "      <td>0.05605</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>...</td>\n",
       "      <td>9.845</td>\n",
       "      <td>25.05</td>\n",
       "      <td>62.86</td>\n",
       "      <td>295.8</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.07993</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.07393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>924632</td>\n",
       "      <td>B</td>\n",
       "      <td>12.880</td>\n",
       "      <td>28.92</td>\n",
       "      <td>82.50</td>\n",
       "      <td>514.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.05824</td>\n",
       "      <td>0.061950</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>...</td>\n",
       "      <td>13.890</td>\n",
       "      <td>35.74</td>\n",
       "      <td>88.84</td>\n",
       "      <td>595.7</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.06493</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>0.07242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>924934</td>\n",
       "      <td>B</td>\n",
       "      <td>10.290</td>\n",
       "      <td>27.61</td>\n",
       "      <td>65.67</td>\n",
       "      <td>321.4</td>\n",
       "      <td>0.09030</td>\n",
       "      <td>0.07658</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>0.027380</td>\n",
       "      <td>...</td>\n",
       "      <td>10.840</td>\n",
       "      <td>34.91</td>\n",
       "      <td>69.57</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.13840</td>\n",
       "      <td>0.17100</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.09127</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.08283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>924964</td>\n",
       "      <td>B</td>\n",
       "      <td>10.160</td>\n",
       "      <td>19.59</td>\n",
       "      <td>64.73</td>\n",
       "      <td>311.7</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.07504</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>...</td>\n",
       "      <td>10.650</td>\n",
       "      <td>22.88</td>\n",
       "      <td>67.88</td>\n",
       "      <td>347.3</td>\n",
       "      <td>0.12650</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.02232</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.06742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>925236</td>\n",
       "      <td>B</td>\n",
       "      <td>9.423</td>\n",
       "      <td>27.88</td>\n",
       "      <td>59.26</td>\n",
       "      <td>271.3</td>\n",
       "      <td>0.08123</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.490</td>\n",
       "      <td>34.24</td>\n",
       "      <td>66.50</td>\n",
       "      <td>330.6</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.07158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.06969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>925277</td>\n",
       "      <td>B</td>\n",
       "      <td>14.590</td>\n",
       "      <td>22.68</td>\n",
       "      <td>96.39</td>\n",
       "      <td>657.1</td>\n",
       "      <td>0.08473</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>...</td>\n",
       "      <td>15.480</td>\n",
       "      <td>27.27</td>\n",
       "      <td>105.90</td>\n",
       "      <td>733.5</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.31710</td>\n",
       "      <td>0.36620</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.08004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>925291</td>\n",
       "      <td>B</td>\n",
       "      <td>11.510</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>...</td>\n",
       "      <td>12.480</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>925292</td>\n",
       "      <td>B</td>\n",
       "      <td>14.050</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>...</td>\n",
       "      <td>15.300</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.13260</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>925311</td>\n",
       "      <td>B</td>\n",
       "      <td>11.200</td>\n",
       "      <td>29.37</td>\n",
       "      <td>70.67</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.07449</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.920</td>\n",
       "      <td>38.30</td>\n",
       "      <td>75.19</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.05494</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>925622</td>\n",
       "      <td>M</td>\n",
       "      <td>15.220</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>...</td>\n",
       "      <td>17.520</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.17000</td>\n",
       "      <td>0.23560</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>926125</td>\n",
       "      <td>M</td>\n",
       "      <td>20.920</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.317400</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>...</td>\n",
       "      <td>24.290</td>\n",
       "      <td>29.41</td>\n",
       "      <td>179.10</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>0.14070</td>\n",
       "      <td>0.41860</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.09873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.560</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.130</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.600</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.092510</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.600</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID diagnosis  radius_mean  radius_sd_error  radius_worst  \\\n",
       "0      842302         M       17.990            10.38        122.80   \n",
       "1      842517         M       20.570            17.77        132.90   \n",
       "2    84300903         M       19.690            21.25        130.00   \n",
       "3    84348301         M       11.420            20.38         77.58   \n",
       "4    84358402         M       20.290            14.34        135.10   \n",
       "5      843786         M       12.450            15.70         82.57   \n",
       "6      844359         M       18.250            19.98        119.60   \n",
       "7    84458202         M       13.710            20.83         90.20   \n",
       "8      844981         M       13.000            21.82         87.50   \n",
       "9    84501001         M       12.460            24.04         83.97   \n",
       "10     845636         M       16.020            23.24        102.70   \n",
       "11   84610002         M       15.780            17.89        103.60   \n",
       "12     846226         M       19.170            24.80        132.40   \n",
       "13     846381         M       15.850            23.95        103.70   \n",
       "14   84667401         M       13.730            22.61         93.60   \n",
       "15   84799002         M       14.540            27.54         96.73   \n",
       "16     848406         M       14.680            20.13         94.74   \n",
       "17   84862001         M       16.130            20.68        108.10   \n",
       "18     849014         M       19.810            22.15        130.00   \n",
       "19    8510426         B       13.540            14.36         87.46   \n",
       "20    8510653         B       13.080            15.71         85.63   \n",
       "21    8510824         B        9.504            12.44         60.34   \n",
       "22    8511133         M       15.340            14.26        102.50   \n",
       "23     851509         M       21.160            23.04        137.20   \n",
       "24     852552         M       16.650            21.38        110.00   \n",
       "25     852631         M       17.140            16.40        116.00   \n",
       "26     852763         M       14.580            21.53         97.41   \n",
       "27     852781         M       18.610            20.25        122.10   \n",
       "28     852973         M       15.300            25.27        102.40   \n",
       "29     853201         M       17.570            15.05        115.00   \n",
       "..        ...       ...          ...              ...           ...   \n",
       "539    921362         B        7.691            25.44         48.34   \n",
       "540    921385         B       11.540            14.44         74.65   \n",
       "541    921386         B       14.470            24.99         95.81   \n",
       "542    921644         B       14.740            25.42         94.70   \n",
       "543    922296         B       13.210            28.06         84.88   \n",
       "544    922297         B       13.870            20.70         89.77   \n",
       "545    922576         B       13.620            23.23         87.19   \n",
       "546    922577         B       10.320            16.35         65.31   \n",
       "547    922840         B       10.260            16.58         65.85   \n",
       "548    923169         B        9.683            19.34         61.05   \n",
       "549    923465         B       10.820            24.21         68.89   \n",
       "550    923748         B       10.860            21.48         68.51   \n",
       "551    923780         B       11.130            22.44         71.49   \n",
       "552    924084         B       12.770            29.43         81.35   \n",
       "553    924342         B        9.333            21.94         59.01   \n",
       "554    924632         B       12.880            28.92         82.50   \n",
       "555    924934         B       10.290            27.61         65.67   \n",
       "556    924964         B       10.160            19.59         64.73   \n",
       "557    925236         B        9.423            27.88         59.26   \n",
       "558    925277         B       14.590            22.68         96.39   \n",
       "559    925291         B       11.510            23.93         74.52   \n",
       "560    925292         B       14.050            27.15         91.38   \n",
       "561    925311         B       11.200            29.37         70.67   \n",
       "562    925622         M       15.220            30.62        103.40   \n",
       "563    926125         M       20.920            25.09        143.00   \n",
       "564    926424         M       21.560            22.39        142.00   \n",
       "565    926682         M       20.130            28.25        131.20   \n",
       "566    926954         M       16.600            28.08        108.30   \n",
       "567    927241         M       20.600            29.33        140.10   \n",
       "568     92751         B        7.760            24.54         47.92   \n",
       "\n",
       "     texture_mean  texture_sd_error  texture_worst  perimeter_mean  \\\n",
       "0          1001.0           0.11840        0.27760        0.300100   \n",
       "1          1326.0           0.08474        0.07864        0.086900   \n",
       "2          1203.0           0.10960        0.15990        0.197400   \n",
       "3           386.1           0.14250        0.28390        0.241400   \n",
       "4          1297.0           0.10030        0.13280        0.198000   \n",
       "5           477.1           0.12780        0.17000        0.157800   \n",
       "6          1040.0           0.09463        0.10900        0.112700   \n",
       "7           577.9           0.11890        0.16450        0.093660   \n",
       "8           519.8           0.12730        0.19320        0.185900   \n",
       "9           475.9           0.11860        0.23960        0.227300   \n",
       "10          797.8           0.08206        0.06669        0.032990   \n",
       "11          781.0           0.09710        0.12920        0.099540   \n",
       "12         1123.0           0.09740        0.24580        0.206500   \n",
       "13          782.7           0.08401        0.10020        0.099380   \n",
       "14          578.3           0.11310        0.22930        0.212800   \n",
       "15          658.8           0.11390        0.15950        0.163900   \n",
       "16          684.5           0.09867        0.07200        0.073950   \n",
       "17          798.8           0.11700        0.20220        0.172200   \n",
       "18         1260.0           0.09831        0.10270        0.147900   \n",
       "19          566.3           0.09779        0.08129        0.066640   \n",
       "20          520.0           0.10750        0.12700        0.045680   \n",
       "21          273.9           0.10240        0.06492        0.029560   \n",
       "22          704.4           0.10730        0.21350        0.207700   \n",
       "23         1404.0           0.09428        0.10220        0.109700   \n",
       "24          904.6           0.11210        0.14570        0.152500   \n",
       "25          912.7           0.11860        0.22760        0.222900   \n",
       "26          644.8           0.10540        0.18680        0.142500   \n",
       "27         1094.0           0.09440        0.10660        0.149000   \n",
       "28          732.4           0.10820        0.16970        0.168300   \n",
       "29          955.1           0.09847        0.11570        0.098750   \n",
       "..            ...               ...            ...             ...   \n",
       "539         170.4           0.08668        0.11990        0.092520   \n",
       "540         402.9           0.09984        0.11200        0.067370   \n",
       "541         656.4           0.08837        0.12300        0.100900   \n",
       "542         668.6           0.08275        0.07214        0.041050   \n",
       "543         538.4           0.08671        0.06877        0.029870   \n",
       "544         584.8           0.09578        0.10180        0.036880   \n",
       "545         573.2           0.09246        0.06747        0.029740   \n",
       "546         324.9           0.09434        0.04994        0.010120   \n",
       "547         320.8           0.08877        0.08066        0.043580   \n",
       "548         285.7           0.08491        0.05030        0.023370   \n",
       "549         361.6           0.08192        0.06602        0.015480   \n",
       "550         360.5           0.07431        0.04227        0.000000   \n",
       "551         378.4           0.09566        0.08194        0.048240   \n",
       "552         507.9           0.08276        0.04234        0.019970   \n",
       "553         264.0           0.09240        0.05605        0.039960   \n",
       "554         514.3           0.08123        0.05824        0.061950   \n",
       "555         321.4           0.09030        0.07658        0.059990   \n",
       "556         311.7           0.10030        0.07504        0.005025   \n",
       "557         271.3           0.08123        0.04971        0.000000   \n",
       "558         657.1           0.08473        0.13300        0.102900   \n",
       "559         403.5           0.09261        0.10210        0.111200   \n",
       "560         600.4           0.09929        0.11260        0.044620   \n",
       "561         386.0           0.07449        0.03558        0.000000   \n",
       "562         716.9           0.10480        0.20870        0.255000   \n",
       "563        1347.0           0.10990        0.22360        0.317400   \n",
       "564        1479.0           0.11100        0.11590        0.243900   \n",
       "565        1261.0           0.09780        0.10340        0.144000   \n",
       "566         858.1           0.08455        0.10230        0.092510   \n",
       "567        1265.0           0.11780        0.27700        0.351400   \n",
       "568         181.0           0.05263        0.04362        0.000000   \n",
       "\n",
       "     perimeter_sd_error           ...             concavity_worst  \\\n",
       "0              0.147100           ...                      25.380   \n",
       "1              0.070170           ...                      24.990   \n",
       "2              0.127900           ...                      23.570   \n",
       "3              0.105200           ...                      14.910   \n",
       "4              0.104300           ...                      22.540   \n",
       "5              0.080890           ...                      15.470   \n",
       "6              0.074000           ...                      22.880   \n",
       "7              0.059850           ...                      17.060   \n",
       "8              0.093530           ...                      15.490   \n",
       "9              0.085430           ...                      15.090   \n",
       "10             0.033230           ...                      19.190   \n",
       "11             0.066060           ...                      20.420   \n",
       "12             0.111800           ...                      20.960   \n",
       "13             0.053640           ...                      16.840   \n",
       "14             0.080250           ...                      15.030   \n",
       "15             0.073640           ...                      17.460   \n",
       "16             0.052590           ...                      19.070   \n",
       "17             0.102800           ...                      20.960   \n",
       "18             0.094980           ...                      27.320   \n",
       "19             0.047810           ...                      15.110   \n",
       "20             0.031100           ...                      14.500   \n",
       "21             0.020760           ...                      10.230   \n",
       "22             0.097560           ...                      18.070   \n",
       "23             0.086320           ...                      29.170   \n",
       "24             0.091700           ...                      26.460   \n",
       "25             0.140100           ...                      22.250   \n",
       "26             0.087830           ...                      17.620   \n",
       "27             0.077310           ...                      21.310   \n",
       "28             0.087510           ...                      20.270   \n",
       "29             0.079530           ...                      20.010   \n",
       "..                  ...           ...                         ...   \n",
       "539            0.013640           ...                       8.678   \n",
       "540            0.025940           ...                      12.260   \n",
       "541            0.038900           ...                      16.220   \n",
       "542            0.030270           ...                      16.510   \n",
       "543            0.032750           ...                      14.370   \n",
       "544            0.023690           ...                      15.050   \n",
       "545            0.024430           ...                      15.350   \n",
       "546            0.005495           ...                      11.250   \n",
       "547            0.024380           ...                      10.830   \n",
       "548            0.009615           ...                      10.930   \n",
       "549            0.008160           ...                      13.030   \n",
       "550            0.000000           ...                      11.660   \n",
       "551            0.022570           ...                      12.020   \n",
       "552            0.014990           ...                      13.870   \n",
       "553            0.012820           ...                       9.845   \n",
       "554            0.023430           ...                      13.890   \n",
       "555            0.027380           ...                      10.840   \n",
       "556            0.011160           ...                      10.650   \n",
       "557            0.000000           ...                      10.490   \n",
       "558            0.037360           ...                      15.480   \n",
       "559            0.041050           ...                      12.480   \n",
       "560            0.043040           ...                      15.300   \n",
       "561            0.000000           ...                      11.920   \n",
       "562            0.094290           ...                      17.520   \n",
       "563            0.147400           ...                      24.290   \n",
       "564            0.138900           ...                      25.450   \n",
       "565            0.097910           ...                      23.690   \n",
       "566            0.053020           ...                      18.980   \n",
       "567            0.152000           ...                      25.740   \n",
       "568            0.000000           ...                       9.456   \n",
       "\n",
       "     concave_points_mean  concave_points_sd_error  concave_points_worst  \\\n",
       "0                  17.33                   184.60                2019.0   \n",
       "1                  23.41                   158.80                1956.0   \n",
       "2                  25.53                   152.50                1709.0   \n",
       "3                  26.50                    98.87                 567.7   \n",
       "4                  16.67                   152.20                1575.0   \n",
       "5                  23.75                   103.40                 741.6   \n",
       "6                  27.66                   153.20                1606.0   \n",
       "7                  28.14                   110.60                 897.0   \n",
       "8                  30.73                   106.20                 739.3   \n",
       "9                  40.68                    97.65                 711.4   \n",
       "10                 33.88                   123.80                1150.0   \n",
       "11                 27.28                   136.50                1299.0   \n",
       "12                 29.94                   151.70                1332.0   \n",
       "13                 27.66                   112.00                 876.5   \n",
       "14                 32.01                   108.80                 697.7   \n",
       "15                 37.13                   124.10                 943.2   \n",
       "16                 30.88                   123.40                1138.0   \n",
       "17                 31.48                   136.80                1315.0   \n",
       "18                 30.88                   186.80                2398.0   \n",
       "19                 19.26                    99.70                 711.2   \n",
       "20                 20.49                    96.09                 630.5   \n",
       "21                 15.66                    65.13                 314.9   \n",
       "22                 19.08                   125.10                 980.9   \n",
       "23                 35.59                   188.00                2615.0   \n",
       "24                 31.56                   177.00                2215.0   \n",
       "25                 21.40                   152.40                1461.0   \n",
       "26                 33.21                   122.40                 896.9   \n",
       "27                 27.26                   139.90                1403.0   \n",
       "28                 36.71                   149.30                1269.0   \n",
       "29                 19.52                   134.90                1227.0   \n",
       "..                   ...                      ...                   ...   \n",
       "539                31.89                    54.49                 223.6   \n",
       "540                19.68                    78.78                 457.8   \n",
       "541                31.73                   113.50                 808.9   \n",
       "542                32.29                   107.40                 826.4   \n",
       "543                37.17                    92.48                 629.6   \n",
       "544                24.75                    99.17                 688.6   \n",
       "545                29.09                    97.58                 729.8   \n",
       "546                21.77                    71.12                 384.9   \n",
       "547                22.04                    71.08                 357.4   \n",
       "548                25.59                    69.10                 364.2   \n",
       "549                31.45                    83.90                 505.6   \n",
       "550                24.77                    74.08                 412.3   \n",
       "551                28.26                    77.80                 436.6   \n",
       "552                36.00                    88.10                 594.7   \n",
       "553                25.05                    62.86                 295.8   \n",
       "554                35.74                    88.84                 595.7   \n",
       "555                34.91                    69.57                 357.6   \n",
       "556                22.88                    67.88                 347.3   \n",
       "557                34.24                    66.50                 330.6   \n",
       "558                27.27                   105.90                 733.5   \n",
       "559                37.16                    82.28                 474.2   \n",
       "560                33.17                   100.20                 706.7   \n",
       "561                38.30                    75.19                 439.6   \n",
       "562                42.79                   128.70                 915.0   \n",
       "563                29.41                   179.10                1819.0   \n",
       "564                26.40                   166.10                2027.0   \n",
       "565                38.25                   155.00                1731.0   \n",
       "566                34.12                   126.70                1124.0   \n",
       "567                39.42                   184.60                1821.0   \n",
       "568                30.37                    59.16                 268.6   \n",
       "\n",
       "     symmetry_mean  symmetry_sd_error  symmetry_worst  fractal_dimension_mean  \\\n",
       "0          0.16220            0.66560         0.71190                 0.26540   \n",
       "1          0.12380            0.18660         0.24160                 0.18600   \n",
       "2          0.14440            0.42450         0.45040                 0.24300   \n",
       "3          0.20980            0.86630         0.68690                 0.25750   \n",
       "4          0.13740            0.20500         0.40000                 0.16250   \n",
       "5          0.17910            0.52490         0.53550                 0.17410   \n",
       "6          0.14420            0.25760         0.37840                 0.19320   \n",
       "7          0.16540            0.36820         0.26780                 0.15560   \n",
       "8          0.17030            0.54010         0.53900                 0.20600   \n",
       "9          0.18530            1.05800         1.10500                 0.22100   \n",
       "10         0.11810            0.15510         0.14590                 0.09975   \n",
       "11         0.13960            0.56090         0.39650                 0.18100   \n",
       "12         0.10370            0.39030         0.36390                 0.17670   \n",
       "13         0.11310            0.19240         0.23220                 0.11190   \n",
       "14         0.16510            0.77250         0.69430                 0.22080   \n",
       "15         0.16780            0.65770         0.70260                 0.17120   \n",
       "16         0.14640            0.18710         0.29140                 0.16090   \n",
       "17         0.17890            0.42330         0.47840                 0.20730   \n",
       "18         0.15120            0.31500         0.53720                 0.23880   \n",
       "19         0.14400            0.17730         0.23900                 0.12880   \n",
       "20         0.13120            0.27760         0.18900                 0.07283   \n",
       "21         0.13240            0.11480         0.08867                 0.06227   \n",
       "22         0.13900            0.59540         0.63050                 0.23930   \n",
       "23         0.14010            0.26000         0.31550                 0.20090   \n",
       "24         0.18050            0.35780         0.46950                 0.20950   \n",
       "25         0.15450            0.39490         0.38530                 0.25500   \n",
       "26         0.15250            0.66430         0.55390                 0.27010   \n",
       "27         0.13380            0.21170         0.34460                 0.14900   \n",
       "28         0.16410            0.61100         0.63350                 0.20240   \n",
       "29         0.12550            0.28120         0.24890                 0.14560   \n",
       "..             ...                ...             ...                     ...   \n",
       "539        0.15960            0.30640         0.33930                 0.05000   \n",
       "540        0.13450            0.21180         0.17970                 0.06918   \n",
       "541        0.13400            0.42020         0.40400                 0.12050   \n",
       "542        0.10600            0.13760         0.16110                 0.10950   \n",
       "543        0.10720            0.13810         0.10620                 0.07958   \n",
       "544        0.12640            0.20370         0.13770                 0.06845   \n",
       "545        0.12160            0.15170         0.10490                 0.07174   \n",
       "546        0.12850            0.08842         0.04384                 0.02381   \n",
       "547        0.14610            0.22460         0.17830                 0.08333   \n",
       "548        0.11990            0.09546         0.09350                 0.03846   \n",
       "549        0.12040            0.16330         0.06194                 0.03264   \n",
       "550        0.10010            0.07348         0.00000                 0.00000   \n",
       "551        0.10870            0.17820         0.15640                 0.06413   \n",
       "552        0.12340            0.10640         0.08653                 0.06498   \n",
       "553        0.11030            0.08298         0.07993                 0.02564   \n",
       "554        0.12270            0.16200         0.24390                 0.06493   \n",
       "555        0.13840            0.17100         0.20000                 0.09127   \n",
       "556        0.12650            0.12000         0.01005                 0.02232   \n",
       "557        0.10730            0.07158         0.00000                 0.00000   \n",
       "558        0.10260            0.31710         0.36620                 0.11050   \n",
       "559        0.12980            0.25170         0.36300                 0.09653   \n",
       "560        0.12410            0.22640         0.13260                 0.10480   \n",
       "561        0.09267            0.05494         0.00000                 0.00000   \n",
       "562        0.14170            0.79170         1.17000                 0.23560   \n",
       "563        0.14070            0.41860         0.65990                 0.25420   \n",
       "564        0.14100            0.21130         0.41070                 0.22160   \n",
       "565        0.11660            0.19220         0.32150                 0.16280   \n",
       "566        0.11390            0.30940         0.34030                 0.14180   \n",
       "567        0.16500            0.86810         0.93870                 0.26500   \n",
       "568        0.08996            0.06444         0.00000                 0.00000   \n",
       "\n",
       "     fractal_dimension_sd_error  fractal_dimension_worst  \n",
       "0                        0.4601                  0.11890  \n",
       "1                        0.2750                  0.08902  \n",
       "2                        0.3613                  0.08758  \n",
       "3                        0.6638                  0.17300  \n",
       "4                        0.2364                  0.07678  \n",
       "5                        0.3985                  0.12440  \n",
       "6                        0.3063                  0.08368  \n",
       "7                        0.3196                  0.11510  \n",
       "8                        0.4378                  0.10720  \n",
       "9                        0.4366                  0.20750  \n",
       "10                       0.2948                  0.08452  \n",
       "11                       0.3792                  0.10480  \n",
       "12                       0.3176                  0.10230  \n",
       "13                       0.2809                  0.06287  \n",
       "14                       0.3596                  0.14310  \n",
       "15                       0.4218                  0.13410  \n",
       "16                       0.3029                  0.08216  \n",
       "17                       0.3706                  0.11420  \n",
       "18                       0.2768                  0.07615  \n",
       "19                       0.2977                  0.07259  \n",
       "20                       0.3184                  0.08183  \n",
       "21                       0.2450                  0.07773  \n",
       "22                       0.4667                  0.09946  \n",
       "23                       0.2822                  0.07526  \n",
       "24                       0.3613                  0.09564  \n",
       "25                       0.4066                  0.10590  \n",
       "26                       0.4264                  0.12750  \n",
       "27                       0.2341                  0.07421  \n",
       "28                       0.4027                  0.09876  \n",
       "29                       0.2756                  0.07919  \n",
       "..                          ...                      ...  \n",
       "539                      0.2790                  0.10660  \n",
       "540                      0.2329                  0.08134  \n",
       "541                      0.3187                  0.10230  \n",
       "542                      0.2722                  0.06956  \n",
       "543                      0.2473                  0.06443  \n",
       "544                      0.2249                  0.08492  \n",
       "545                      0.2642                  0.06953  \n",
       "546                      0.2681                  0.07399  \n",
       "547                      0.2691                  0.09479  \n",
       "548                      0.2552                  0.07920  \n",
       "549                      0.3059                  0.07626  \n",
       "550                      0.2458                  0.06592  \n",
       "551                      0.3169                  0.08032  \n",
       "552                      0.2407                  0.06484  \n",
       "553                      0.2435                  0.07393  \n",
       "554                      0.2372                  0.07242  \n",
       "555                      0.2226                  0.08283  \n",
       "556                      0.2262                  0.06742  \n",
       "557                      0.2475                  0.06969  \n",
       "558                      0.2258                  0.08004  \n",
       "559                      0.2112                  0.08732  \n",
       "560                      0.2250                  0.08321  \n",
       "561                      0.1566                  0.05905  \n",
       "562                      0.4089                  0.14090  \n",
       "563                      0.2929                  0.09873  \n",
       "564                      0.2060                  0.07115  \n",
       "565                      0.2572                  0.06637  \n",
       "566                      0.2218                  0.07820  \n",
       "567                      0.4087                  0.12400  \n",
       "568                      0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import pandas and numpy modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load in the data file and header file provided\n",
    "text_file = open(\"field_names.txt\", \"r\")\n",
    "lines = text_file.readlines()\n",
    "# Replace newline character at the end of each header\n",
    "headers = [h.replace(\"\\n\",\"\") for h in lines]\n",
    "# Load data and attach headers to dataframe\n",
    "dataframe = pd.read_csv('breast-cancer.csv', names=headers)\n",
    "# Print data table with headers\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "Computed mean and median smoothness and compactness for benign and malignant tumors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into benign and malignant feature vectors\n",
    "dataframe_m = dataframe.loc[dataframe['diagnosis'] == \"M\"]\n",
    "dataframe_b = dataframe.loc[dataframe['diagnosis'] == \"B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean smoothness for malignant tumors: 4.323929\n",
      "Median smoothness for malignant tumors: 3.679500\n",
      "Mean smoothness for benign tumors: 2.000321\n",
      "Median smoothness for benign tumors: 1.851000\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean and median smoothness for benign and malignant tumors\n",
    "print(\"Mean smoothness for malignant tumors: %f\" % dataframe_m['smoothness_mean'].mean())\n",
    "print(\"Median smoothness for malignant tumors: %f\" % dataframe_m['smoothness_mean'].median())\n",
    "print(\"Mean smoothness for benign tumors: %f\" % dataframe_b['smoothness_mean'].mean())\n",
    "print(\"Median smoothness for benign tumors: %f\" % dataframe_b['smoothness_mean'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean compactness for malignant tumors: 0.032281\n",
      "Median compactness for malignant tumors: 0.028590\n",
      "Mean compactness for benign tumors: 0.021438\n",
      "Median compactness for benign tumors: 0.016310\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean and median compactness for benign and malignant tumors\n",
    "print(\"Mean compactness for malignant tumors: %f\" % dataframe_m['compactness_mean'].mean())\n",
    "print(\"Median compactness for malignant tumors: %f\" % dataframe_m['compactness_mean'].median())\n",
    "print(\"Mean compactness for benign tumors: %f\" % dataframe_b['compactness_mean'].mean())\n",
    "print(\"Median compactness for benign tumors: %f\" % dataframe_b['compactness_mean'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed from the above values, the mean and median smoothness and compactness for benign and malignant tumors are different. Using the mean and median method on the specified columns in the dataframe, we are able to obtain these values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:\n",
    "Function to generate bootstrap samples of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>radius_sd_error</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>texture_sd_error</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>perimeter_sd_error</th>\n",
       "      <th>...</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>concave_points_sd_error</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>symmetry_sd_error</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>fractal_dimension_sd_error</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>923748</td>\n",
       "      <td>B</td>\n",
       "      <td>10.86</td>\n",
       "      <td>21.48</td>\n",
       "      <td>68.51</td>\n",
       "      <td>360.5</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.04227</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.66</td>\n",
       "      <td>24.77</td>\n",
       "      <td>74.08</td>\n",
       "      <td>412.3</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>857392</td>\n",
       "      <td>M</td>\n",
       "      <td>18.22</td>\n",
       "      <td>18.70</td>\n",
       "      <td>120.30</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.14850</td>\n",
       "      <td>0.17720</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>...</td>\n",
       "      <td>20.60</td>\n",
       "      <td>24.13</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.22970</td>\n",
       "      <td>0.26230</td>\n",
       "      <td>0.13250</td>\n",
       "      <td>0.3021</td>\n",
       "      <td>0.07987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>8910988</td>\n",
       "      <td>M</td>\n",
       "      <td>21.75</td>\n",
       "      <td>20.99</td>\n",
       "      <td>147.30</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>0.09401</td>\n",
       "      <td>0.19610</td>\n",
       "      <td>0.21950</td>\n",
       "      <td>0.10880</td>\n",
       "      <td>...</td>\n",
       "      <td>28.19</td>\n",
       "      <td>28.18</td>\n",
       "      <td>195.90</td>\n",
       "      <td>2384.0</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>0.47250</td>\n",
       "      <td>0.58070</td>\n",
       "      <td>0.18410</td>\n",
       "      <td>0.2833</td>\n",
       "      <td>0.08858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>887181</td>\n",
       "      <td>M</td>\n",
       "      <td>15.66</td>\n",
       "      <td>23.20</td>\n",
       "      <td>110.20</td>\n",
       "      <td>773.5</td>\n",
       "      <td>0.11090</td>\n",
       "      <td>0.31140</td>\n",
       "      <td>0.31760</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>...</td>\n",
       "      <td>19.85</td>\n",
       "      <td>31.64</td>\n",
       "      <td>143.70</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.51720</td>\n",
       "      <td>0.61810</td>\n",
       "      <td>0.24620</td>\n",
       "      <td>0.3277</td>\n",
       "      <td>0.10190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>857343</td>\n",
       "      <td>B</td>\n",
       "      <td>11.76</td>\n",
       "      <td>21.60</td>\n",
       "      <td>74.72</td>\n",
       "      <td>427.9</td>\n",
       "      <td>0.08637</td>\n",
       "      <td>0.04966</td>\n",
       "      <td>0.01657</td>\n",
       "      <td>0.01115</td>\n",
       "      <td>...</td>\n",
       "      <td>12.98</td>\n",
       "      <td>25.72</td>\n",
       "      <td>82.98</td>\n",
       "      <td>516.5</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.05523</td>\n",
       "      <td>0.03715</td>\n",
       "      <td>0.2433</td>\n",
       "      <td>0.06563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID diagnosis  radius_mean  radius_sd_error  radius_worst  \\\n",
       "550   923748         B        10.86            21.48         68.51   \n",
       "53    857392         M        18.22            18.70        120.30   \n",
       "272  8910988         M        21.75            20.99        147.30   \n",
       "258   887181         M        15.66            23.20        110.20   \n",
       "50    857343         B        11.76            21.60         74.72   \n",
       "\n",
       "     texture_mean  texture_sd_error  texture_worst  perimeter_mean  \\\n",
       "550         360.5           0.07431        0.04227         0.00000   \n",
       "53         1033.0           0.11480        0.14850         0.17720   \n",
       "272        1491.0           0.09401        0.19610         0.21950   \n",
       "258         773.5           0.11090        0.31140         0.31760   \n",
       "50          427.9           0.08637        0.04966         0.01657   \n",
       "\n",
       "     perimeter_sd_error           ...             concavity_worst  \\\n",
       "550             0.00000           ...                       11.66   \n",
       "53              0.10600           ...                       20.60   \n",
       "272             0.10880           ...                       28.19   \n",
       "258             0.13770           ...                       19.85   \n",
       "50              0.01115           ...                       12.98   \n",
       "\n",
       "     concave_points_mean  concave_points_sd_error  concave_points_worst  \\\n",
       "550                24.77                    74.08                 412.3   \n",
       "53                 24.13                   135.10                1321.0   \n",
       "272                28.18                   195.90                2384.0   \n",
       "258                31.64                   143.70                1226.0   \n",
       "50                 25.72                    82.98                 516.5   \n",
       "\n",
       "     symmetry_mean  symmetry_sd_error  symmetry_worst  fractal_dimension_mean  \\\n",
       "550         0.1001            0.07348         0.00000                 0.00000   \n",
       "53          0.1280            0.22970         0.26230                 0.13250   \n",
       "272         0.1272            0.47250         0.58070                 0.18410   \n",
       "258         0.1504            0.51720         0.61810                 0.24620   \n",
       "50          0.1085            0.08615         0.05523                 0.03715   \n",
       "\n",
       "     fractal_dimension_sd_error  fractal_dimension_worst  \n",
       "550                      0.2458                  0.06592  \n",
       "53                       0.3021                  0.07987  \n",
       "272                      0.2833                  0.08858  \n",
       "258                      0.3277                  0.10190  \n",
       "50                       0.2433                  0.06563  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_bootstrap_samples(dataframe, N=5):\n",
    "    \"\"\"Function to generate bootstrap samples of the data.\n",
    "    Bootstrapping relies on random sampling with replacement.\n",
    "\n",
    "    Args:\n",
    "        param1: The dataframe.\n",
    "        param2: The number of samples to generate.\n",
    "\n",
    "    Returns:\n",
    "        A dataframe with N samples.\n",
    "\n",
    "    \"\"\"\n",
    "    sample = dataframe.sample(n=N, replace=True)\n",
    "    return sample\n",
    "\n",
    "# Test function output on dataframe\n",
    "generate_bootstrap_samples(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:\n",
    "Exploratory Analysis. Variables that are predictive of a malignant tumor:\n",
    "\n",
    "RW = radius_worst,\n",
    "TM =  texture_mean,\n",
    "CPSE = concave_points_sd_error,\n",
    "CPW = concave_points_worst\n",
    "\n",
    "From observation, the variables previously outlined are much higher in the case of malignant tumors. This relationship is shown in the following bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_benign = [dataframe_b['radius_worst'].mean(), dataframe_b['texture_mean'].mean(), \n",
    "                dataframe_b['concave_points_sd_error'].mean(), \n",
    "                dataframe_b['concave_points_worst'].mean()]\n",
    "means_malignant = [dataframe_m['radius_worst'].mean(), dataframe_m['texture_mean'].mean(), \n",
    "                dataframe_m['concave_points_sd_error'].mean(), \n",
    "                dataframe_m['concave_points_worst'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1171d4810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "n_groups = 4\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.2\n",
    "opacity = 0.8\n",
    "rects1 = plt.bar(index, means_malignant, bar_width, alpha=opacity, \n",
    "                 color='r', label='Malignant')\n",
    "rects2 = plt.bar(index + bar_width, means_benign, bar_width, alpha=opacity,\n",
    "                 color='g', label='Benign')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Means')\n",
    "plt.title('Mean Values by Features')\n",
    "plt.xticks(index + bar_width, ('RW', 'TM', 'CPSE', 'CPW'), rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection with Variance Threshold.\n",
    "VarianceThreshold is a simple baseline approach to feature selection. It removes all features whose variance does not meet some threshold. By default, it removes features that have the same value in all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 30 artists>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1167cad90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "# Split the dataset into X (the feature matrix) and y (the labels)\n",
    "X_m = dataframe_m.iloc[:, 2:]\n",
    "X_m = X_m.values\n",
    "selector = VarianceThreshold()\n",
    "selector.fit_transform(X_m)\n",
    "selector.variances_\n",
    "%matplotlib inline\n",
    "N = len(selector.variances_)\n",
    "x = range(selector.variances_.shape[0])\n",
    "width = 1/1.5\n",
    "plt.title(\"Feature Variance\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.bar(x, selector.variances_, width, color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 features that are predictive of a malignant tumor:\n",
      "1. concave_points_mean\n",
      "2. radius_sd_error\n",
      "3. area_worst\n"
     ]
    }
   ],
   "source": [
    "# find indices of features with top variances\n",
    "indices = np.argsort(selector.variances_)[::-1]\n",
    "print(\"3 features that are predictive of a malignant tumor:\")\n",
    "for i, j in enumerate(indices[:3]):\n",
    "    print(\"%d. %s\" % (i+1, headers[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Create X (features) and y (targets) matrices \n",
    "X = dataframe.iloc[:, 2:]\n",
    "X = X.values\n",
    "y_labels = dataframe.iloc[:, 1:2].values.flatten()\n",
    "# Create label indicator matrix from list of malignant and benign labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_labels)\n",
    "# Split the dataset into random train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection with univariate feature selection.\n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests. SelectKBest selects features according to the k highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 highest scoring features:\n",
      "1. concave_points_mean\n",
      "2. radius_sd_error\n",
      "3. area_worst\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "selector = SelectKBest(f_classif, k=3)\n",
    "selector.fit(X, y_encoded)\n",
    "indices = np.argsort(selector.scores_)[::-1]\n",
    "print(\"Top 3 highest scoring features:\")\n",
    "for i, j in enumerate(indices[:3]):\n",
    "    print(\"%d. %s\" % (i+1, headers[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Modeling\n",
    "### Random Forest Classifier:\n",
    "A Random forest classifier (RFC) is an ensemble classifier that consists of many decision trees and outputs the class which represents the mode of the classes output by individual trees.\n",
    "#### Advantages:\n",
    "A RFC has many advantages. It is one of the most accurate ensemble classifiers and can be trained efficiently fast on large datasets. It can handle thousands of input variables without variable deletion. It gives estimates of what variables are important in the classification. It has an effective method for estimating missing data and maintains accuracy when a large proportion of the data are missing. It has methods for balancing error in class population in skewed datasets. It can be used to compute proximities between pairs of feature vectors, which in turn can be used in an unsupervised fashion like clustering.\n",
    "\n",
    "#### Disadvantages:\n",
    "RFC is more complex model. Unlike single decision trees, it is hard to visualize and trace back individual predictions. It is more computationally expensive. It can overfit on noisy datasets. In the case of categorical variables with different levels, RFC can be biased in favor of attributes with high levels.\n",
    "\n",
    "#### Handling overfitting:\n",
    "Overfitting describes the situation where the model learns the training data very well but fails to generalized on unseen test data. One of the more obvious way to remedy this problem is to get more training data an inspect how the results vary through a learning curve. In the case of RFC, we can explore tuning the following parameters with a cross validation set prior to testing:\n",
    "##### n_estimators:\n",
    "In general the more trees the less likely the algorithm is to overfit, so increasing this parameter could help the model yield better results.\n",
    "##### max_features:\n",
    "Reducing the number of features also helps address the problem of over-fitting; however one must avoid making this number too small as it might introduce under-fitting.\n",
    "##### max_depth and min_samples_leaf:\n",
    "These parameters reduce the model complexity and lowers the risk of over-fitting on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance ranking:\n",
      "1. feature 22: concave_points_sd_error (0.146039)\n",
      "2. feature 20: concavity_worst (0.138702)\n",
      "3. feature 27: fractal_dimension_mean (0.115670)\n",
      "Model training accuracy: 1.000000\n",
      "Model test accuracy: 0.956140\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_1 = RandomForestClassifier(n_estimators=200)\n",
    "classifier_1.fit(X_train, y_train)\n",
    "importances = classifier_1.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature importance ranking:\")\n",
    "for f in range(3):\n",
    "    print(\"%d. feature %d: %s (%f)\" % (f + 1, indices[f], headers[2:][indices[f]], importances[indices[f]]))\n",
    "    \n",
    "accuracy_train = classifier_1.score(X_train, y_train)\n",
    "print(\"Model training accuracy: %f\" % accuracy_train)\n",
    "accuracy_test = classifier_1.score(X_test, y_test)\n",
    "print(\"Model test accuracy: %f\" % accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression:\n",
    "Logistic regression is the classification counterpart to linear regression. Predictions are mapped to be between 0 and 1 through the logistic function, which means that predictions can be interpreted as class probabilities.\n",
    "#### Advantages:\n",
    "Outputs have a nice probabilistic interpretation, and the algorithm can be regularized to avoid overfitting. Logistic models can be updated easily with new data using stochastic gradient descent.\n",
    "#### Disadvantages:\n",
    "Logistic regression tends to underperform when there are multiple or non-linear decision boundaries. They are not flexible enough to naturally capture more complex relationships.\n",
    "#### Recursive Feature Elimination (RFE)\n",
    "Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coefficient attribute or through a feature importance attribute. Then, the least important features are removed from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n",
    "#### Handling overfitting:\n",
    "In the case of logistic regression, to address the problem of over-fitting one could try reducing number of features in the dataset. Using a feature selection technique like the one previously described could also be a good strategy. Regularization is another good option. It adds a penalty on the different parameters of the model to reduce the freedom of the model. Hence, the model will be less likely to fit to noise in the training data with improved generalization abilities on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 features:\n",
      "1. feature 6: perimeter_mean\n",
      "2. feature 20: concavity_worst\n",
      "3. feature 26: symmetry_worst\n",
      "Model training accuracy: 0.958242\n",
      "Model test accuracy: 0.956140\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# feature extraction\n",
    "classifier_2 = LogisticRegression()\n",
    "rfe = RFE(classifier_2, 3)\n",
    "fit = rfe.fit(X_train, y_train)\n",
    "indices = np.nonzero(fit.support_)[0]\n",
    "print(\"Top 3 features:\")\n",
    "for f in range(3):\n",
    "    print(\"%d. feature %d: %s\" % (f + 1, indices[f], headers[2:][indices[f]]))\n",
    "\n",
    "classifier_2.fit(X_train, y_train)\n",
    "accuracy_train = classifier_2.score(X_train, y_train)\n",
    "print(\"Model training accuracy: %f\" % accuracy_train)\n",
    "accuracy_test = classifier_2.score(X_test, y_test)\n",
    "print(\"Model test accuracy: %f\" % accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "#### Analysis limitations (technical audience):\n",
    "Some additional techniques to improve and analyze model performance:\n",
    "* Learning curves: help inspect model accuracy as we increase the size of training examples. The error rate should generally decrease as we increase the size of training examples. \n",
    "* Hyper-parameter tuning: a hyperparameter is parameter whose value is set before the learning process begins. Hyperparameter tuning finds an optimal value for the parameter during cross-validation on the given dataset.\n",
    "* Validation curves: help determine training and test scores for varying parameter values.\n",
    "* Area Under ROC Curve: a performance metric for binary classification problems. It represents a models ability to discriminate between positive and negative classes. An area of 1.0 represents a model that made all predictions perfectly. An area of 0.5 represents a model as good as random.\n",
    "* Confusion Matrix: a confusion matrix is a handy presentation of the accuracy of a model with two or more classes.\n",
    "* Scikit-learn Classification Report: a function displaying the precision, recall, f1-score and support for each class in the dataset.\n",
    "\n",
    "\n",
    "#### To Non-Technical Audiences\n",
    "In this exercise, we analyzed measurements of breast cancer cells. For each cell, we tried to determine whether it is malignant or benign. To achieve this, we employed two classification techniques: random forest and logistic regression. \n",
    "\n",
    "\n",
    "* Random Forest uses a group of decision trees, where each tree is a bit different from the next. When a set of attributes is passed to the model as unified feature vector, we take the majority vote of the ensemble to get a final prediction. Each tree in the model only sees part of the data (randomly sampled with replacement), and we used a subset of the features for each tree. In our current analysis, the model performed perfectly on the training data and achieved an accuracy of 96% on the test data.\n",
    "* Logistic regression provides the probability that the given input feature vector belongs to a certain class. The central premise of the model is the assumption that the input space can be separated into homogeneous regions, one for each class, by a linear boundary. In our experiment, the model achieved 96% accuracy on both the training and test sets.\n",
    "\n",
    "In the RFC model concave_points_sd_error, concavity_worst and fractal_dimension_mean were highly correlated with the diagnosis, whereas perimeter_mean, concavity_worst and symmetry_worst were found to be the top important features in case of logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
